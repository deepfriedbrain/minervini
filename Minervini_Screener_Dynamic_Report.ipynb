{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8aae94",
   "metadata": {},
   "source": [
    "Source Repo: https://github.com/wholidi/Project/tree/main/Minervini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"yfinance_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def get_yfinance_data(symbol: str, start_date: str, end_date: str, interval: str = \"1d\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch historical OHLCV data for a given ticker from Yahoo Finance, \n",
    "    using a cached file if available.\n",
    "\n",
    "    If a cached CSV file exists for the symbol, data is loaded from it.\n",
    "    Otherwise, live data is fetched from Yahoo Finance and saved to the cache.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): Ticker symbol (e.g., \"AAPL\", \"SPY\").\n",
    "        start_date (str): Start date for historical data in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date for historical data in 'YYYY-MM-DD' format.\n",
    "        interval (str): Data interval (\"1d\", \"1wk\", \"1mo\", etc.). Default is \"1d\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with timestamp index and columns: open, high, low, close, volume.\n",
    "                      Returns empty DataFrame if no data is found.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(DATA_DIR, f\"{symbol}.csv\")  # 🔹 File name without date\n",
    "\n",
    "    # Load from cache if available\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        print(f\"📄 Loaded {symbol} data from file ({len(df)} rows)\")\n",
    "        return df\n",
    "\n",
    "    # Fetch live data\n",
    "    print(f\"Calling live API for {symbol}\")\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    df = ticker.history(start=start_date, end=end_date, interval=interval)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"⚠️ No data found for {symbol}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df.index = df.index.tz_localize(None)  # remove timezone if present\n",
    "    df = df.rename(columns={\n",
    "        \"Open\": \"open\",\n",
    "        \"High\": \"high\",\n",
    "        \"Low\": \"low\",\n",
    "        \"Close\": \"close\",\n",
    "        \"Volume\": \"volume\"\n",
    "    })\n",
    "\n",
    "    df = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "    # Save to cache\n",
    "    df.to_csv(file_path)\n",
    "    print(f\"✅ Saved {symbol} data to {file_path} ({len(df)} rows)\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35161e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Index return using Yahoo Finance (SPY as proxy for S&P 500)\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "index_symbol = \"SPY\"\n",
    "index_df = get_yfinance_data(index_symbol, start_date=start_date, end_date=end_date)\n",
    "\n",
    "# Ensure 'close' is float\n",
    "index_df[\"close\"] = index_df[\"close\"].astype(float)\n",
    "\n",
    "# Compute daily percent change\n",
    "index_df[\"Percent Change\"] = index_df[\"close\"].pct_change()\n",
    "\n",
    "# Compute cumulative return\n",
    "index_return = (index_df[\"Percent Change\"] + 1).cumprod().iloc[-1]\n",
    "\n",
    "print(f\"S&P 500 proxy return (SPY): {index_return:.2f}x\")\n",
    "print(index_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "TICKERS_FILE = \"tickers_sp500.csv\"  # 🔹 file to store full table with sanitized tickers\n",
    "\n",
    "def tickers_sp500() -> list:\n",
    "    \"\"\"\n",
    "    Fetch S&P 500 tickers from Wikipedia, cache the full table to a CSV file\n",
    "    with sanitized tickers, and return a list of tickers for Yahoo Finance.\n",
    "\n",
    "    Returns:\n",
    "        list: List of ticker symbols formatted for Yahoo Finance (e.g., BRK-B instead of BRK.B).\n",
    "    \"\"\"\n",
    "    # 🔹 Load from file if exists\n",
    "    if os.path.exists(TICKERS_FILE):\n",
    "        df = pd.read_csv(TICKERS_FILE)\n",
    "        tickers = df['Symbol'].dropna().tolist()\n",
    "        print(f\"📄 Loaded {len(tickers)} tickers from {TICKERS_FILE}\")\n",
    "        return tickers\n",
    "\n",
    "    # 🔹 Fetch live data from Wikipedia\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    html = requests.get(url, headers=headers).text\n",
    "    df_list = pd.read_html(StringIO(html), header=0)\n",
    "    df = df_list[0]\n",
    "\n",
    "    # 🔹 Sanitize tickers in the DataFrame\n",
    "    df['Symbol'] = df['Symbol'].str.replace('.', '-', regex=False)\n",
    "\n",
    "    # 🔹 Save full table with sanitized tickers to CSV\n",
    "    df.to_csv(TICKERS_FILE, index=False)\n",
    "    print(f\"✅ Saved full S&P 500 table with sanitized tickers to {TICKERS_FILE}\")\n",
    "\n",
    "    # 🔹 Return list of tickers\n",
    "    tickers = df['Symbol'].dropna().tolist()\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a15bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = tickers_sp500()\n",
    "print(f\"✅ Loaded {len(tickers)} S&P 500 tickers\")\n",
    "print(tickers[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global dictionary to store all ticker data\n",
    "yahoo_data = {}\n",
    "successful_tickers = []\n",
    "failed_tickers = []\n",
    "\n",
    "def load_yahoo_data(tickers):\n",
    "    \"\"\"\n",
    "    Fetch data once and store in global yahoo_data dictionary.\n",
    "    Writes passed and failed tickers to text files.\n",
    "    \"\"\"\n",
    "    global yahoo_data\n",
    "\n",
    "    for symbol in tickers:\n",
    "        df = get_yfinance_data(symbol, start_date=start_date, end_date=end_date)\n",
    "\n",
    "        if df.empty or \"close\" not in df.columns:\n",
    "            print(f\"⚠️ Skipping {symbol}: No data or bad format\")\n",
    "            failed_tickers.append(symbol)\n",
    "            continue\n",
    "\n",
    "        yahoo_data[symbol] = df\n",
    "        successful_tickers.append(symbol)\n",
    "        print(f\"✅ Loaded {symbol} successfully\")\n",
    "\n",
    "    # Write failed tickers to file\n",
    "    with open(\"failed_tickers.txt\", \"w\") as f:\n",
    "        for ticker in failed_tickers:\n",
    "            f.write(f\"{ticker}\\n\")\n",
    "\n",
    "    # Write successful tickers to file (optional)\n",
    "    with open(\"successful_tickers.txt\", \"w\") as f:\n",
    "        for ticker in successful_tickers:\n",
    "            f.write(f\"{ticker}\\n\")\n",
    "\n",
    "    print(f\"\\n📄 {len(successful_tickers)} tickers loaded successfully and saved to successful_tickers.txt\")\n",
    "    print(f\"📄 {len(failed_tickers)} tickers failed and saved to failed_tickers.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7108336",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_yahoo_data(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rs(index_return, start_date, end_date, index_symbol=\"SPY\"):\n",
    "    \"\"\"\n",
    "    Calculate RS scores using preloaded yahoo_data and precomputed index_return.\n",
    "    Only processes successful tickers from load_yahoo_data().\n",
    "    \"\"\"\n",
    "    global yahoo_data, successful_tickers\n",
    "\n",
    "    returns_multiples = []\n",
    "\n",
    "    for symbol in successful_tickers:\n",
    "        if symbol == index_symbol:\n",
    "            continue  # skip the index itself\n",
    "\n",
    "        df_subset = yahoo_data[symbol].loc[start_date:end_date].copy()\n",
    "        df_subset[\"close\"] = df_subset[\"close\"].astype(float)\n",
    "        df_subset[\"Percent Change\"] = df_subset[\"close\"].pct_change()\n",
    "        stock_return = (df_subset[\"Percent Change\"] + 1).cumprod().iloc[-1]\n",
    "        rs_score = stock_return / index_return\n",
    "        returns_multiples.append(rs_score)\n",
    "        print(f\"✅ {symbol} processed – RS Score: {rs_score:.2f}\")\n",
    "\n",
    "    return returns_multiples\n",
    "\n",
    "returns_multiples = calculate_rs(index_return, start_date, end_date)\n",
    "print(f\"\\nCalculated RS scores for {len(successful_tickers)} tickers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41faf96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Create RS Rating DataFrame\n",
    "rs_df = pd.DataFrame({\n",
    "    'Ticker': successful_tickers,\n",
    "    'Returns_multiple': returns_multiples\n",
    "})\n",
    "rs_df['RS_Rating'] = rs_df['Returns_multiple'].rank(pct=True) * 100\n",
    "\n",
    "# ✅ Filter top 30% by RS Rating (adjust quantile as needed)\n",
    "top_30_percent = rs_df['RS_Rating'].quantile(0.7)\n",
    "rs_top_df = rs_df[rs_df['RS_Rating'] >= top_30_percent]\n",
    "\n",
    "print(rs_top_df[:10])\n",
    "# Print sorted top RS stocks\n",
    "print(rs_top_df.sort_values(by='RS_Rating', ascending=False).head(10))\n",
    "\n",
    "# ✅ Export all RS-rated stocks without filtering\n",
    "rs_df.to_csv(\"rs_full_list.csv\", index=False)\n",
    "print(f\"📊 Full RS stock list: {len(rs_df)} saved to rs_full_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce51030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Initialize export DataFrame\n",
    "detailedExportList = pd.DataFrame(columns=[\n",
    "    'Stock', 'Price', '50 Day MA', '150 Day MA', '200 Day MA', \n",
    "    '52 Week Low', '52 Week High', 'RS_Rating', 'Status'  # 🔹 CHANGED\n",
    "])\n",
    "\n",
    "# ✅ Iterate only over top RS stocks\n",
    "for stock in rs_top_df['Ticker']:\n",
    "    try:\n",
    "        # Use already loaded data\n",
    "        df = yahoo_data.get(stock)\n",
    "        if df is None or df.empty:\n",
    "            print(f\"⚠️ No data for {stock}, skipping\")\n",
    "            continue\n",
    "\n",
    "        # Clean and prep columns\n",
    "        df.columns = [col.split(\". \")[-1] for col in df.columns]\n",
    "        df[['close', 'high', 'low']] = df[['close', 'high', 'low']].astype(float)\n",
    "\n",
    "        # Compute SMAs\n",
    "        df['SMA_50'] = df['close'].rolling(window=50).mean()\n",
    "        df['SMA_150'] = df['close'].rolling(window=150).mean()\n",
    "        df['SMA_200'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "        # Grab latest values\n",
    "        currentClose = df['close'].iloc[-1]\n",
    "        SMA_50 = df['SMA_50'].iloc[-1]\n",
    "        SMA_150 = df['SMA_150'].iloc[-1]\n",
    "        SMA_200 = df['SMA_200'].iloc[-1]\n",
    "\n",
    "        # 52-week high/low\n",
    "        low_52week = round(df['low'].iloc[-260:].min(), 2)\n",
    "        high_52week = round(df['high'].iloc[-260:].max(), 2)\n",
    "\n",
    "        # RS Rating\n",
    "        RS_Rating = round(rs_top_df.loc[rs_top_df['Ticker'] == stock, 'RS_Rating'].iloc[0])\n",
    "\n",
    "        # Handle insufficient SMA data\n",
    "        if pd.isnull([SMA_50, SMA_150, SMA_200]).any():\n",
    "            status_msg = f\"❌ Skipped {stock}: Not enough data for SMAs ({len(df)} rows)\"\n",
    "            print(status_msg)\n",
    "        else:\n",
    "            # Compare 200-day SMA 20 days ago\n",
    "            SMA_200_20 = df['SMA_200'].iloc[-20] if len(df) >= 220 else 0\n",
    "\n",
    "            # Minervini conditions\n",
    "            condition_1 = currentClose > SMA_150 > SMA_200\n",
    "            condition_2 = SMA_150 > SMA_200\n",
    "            condition_3 = SMA_200 > SMA_200_20\n",
    "            condition_4 = SMA_50 > SMA_150 > SMA_200\n",
    "            condition_5 = currentClose > SMA_50\n",
    "            condition_6 = currentClose >= 1.3 * low_52week\n",
    "            condition_7 = currentClose >= 0.75 * high_52week\n",
    "\n",
    "            conditions = [condition_1, condition_2, condition_3, condition_4,\n",
    "                          condition_5, condition_6, condition_7]\n",
    "\n",
    "            if all(conditions):\n",
    "                status_msg = \"✅ Passed Minervini\"\n",
    "                print(f\"✅ {stock} passed Minervini\")\n",
    "            else:\n",
    "                failed = [str(i+1) for i, c in enumerate(conditions) if not c]\n",
    "                status_msg = f\"❌ Failed Minervini conditions: {', '.join(failed)}\"\n",
    "                print(f\"❌ {stock} failed Minervini: {', '.join(failed)}\")\n",
    "\n",
    "        # Append to export list once per stock\n",
    "        detailedExportList = pd.concat([detailedExportList, pd.DataFrame([{\n",
    "            'Stock': stock,\n",
    "            'Price': currentClose,\n",
    "            '50 Day MA': SMA_50,\n",
    "            '150 Day MA': SMA_150,\n",
    "            '200 Day MA': SMA_200,\n",
    "            '52 Week Low': low_52week,\n",
    "            '52 Week High': high_52week,\n",
    "            'RS_Rating': RS_Rating,\n",
    "            'Status': status_msg\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not process {stock}: {e}\")\n",
    "\n",
    "# ✅ Split results\n",
    "passed_df = detailedExportList[detailedExportList['Status'] == \"✅ Passed Minervini\"]\n",
    "failed_df = detailedExportList[detailedExportList['Status'] != \"✅ Passed Minervini\"]\n",
    "\n",
    "# # 📤 Export to Excel\n",
    "# passed_df.to_excel(\"Minervini_Passed.xlsx\", index=False)\n",
    "# failed_df.to_excel(\"Minervini_Failed.xlsx\", index=False)\n",
    "\n",
    "# 📤 Export to CSV\n",
    "passed_df.to_csv(\"Minervini_Passed.csv\", index=False)\n",
    "failed_df.to_csv(\"Minervini_Failed.csv\", index=False)\n",
    "\n",
    "print(f\"\\n📄 {len(passed_df)} stocks passed Minervini, saved to Minervini_Passed.csv\")\n",
    "print(f\"📄 {len(failed_df)} stocks failed Minervini, saved to Minervini_Failed.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
