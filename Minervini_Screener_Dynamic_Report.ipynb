{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8aae94",
   "metadata": {},
   "source": [
    "Source Repo: https://github.com/wholidi/Project/tree/main/Minervini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"yfinance_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def get_yfinance_data(symbol: str, start_date: str, end_date: str, interval: str = \"1d\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch historical OHLCV data for a given ticker from Yahoo Finance, \n",
    "    using a cached file if available.\n",
    "\n",
    "    If a cached CSV file exists for the symbol, data is loaded from it.\n",
    "    Otherwise, live data is fetched from Yahoo Finance and saved to the cache.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): Ticker symbol (e.g., \"AAPL\", \"SPY\").\n",
    "        start_date (str): Start date for historical data in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date for historical data in 'YYYY-MM-DD' format.\n",
    "        interval (str): Data interval (\"1d\", \"1wk\", \"1mo\", etc.). Default is \"1d\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with timestamp index and columns: open, high, low, close, volume.\n",
    "                      Returns empty DataFrame if no data is found.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(DATA_DIR, f\"{symbol}.csv\")  # üîπ File name without date\n",
    "\n",
    "    # Load from cache if available\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        print(f\"üìÑ Loaded {symbol} data from file ({len(df)} rows)\")\n",
    "        return df\n",
    "\n",
    "    # Fetch live data\n",
    "    print(f\"Calling live API for {symbol}\")\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    df = ticker.history(start=start_date, end=end_date, interval=interval)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è No data found for {symbol}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df.index = df.index.tz_localize(None)  # remove timezone if present\n",
    "    df = df.rename(columns={\n",
    "        \"Open\": \"open\",\n",
    "        \"High\": \"high\",\n",
    "        \"Low\": \"low\",\n",
    "        \"Close\": \"close\",\n",
    "        \"Volume\": \"volume\"\n",
    "    })\n",
    "\n",
    "    df = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "    # Save to cache\n",
    "    df.to_csv(file_path)\n",
    "    print(f\"‚úÖ Saved {symbol} data to {file_path} ({len(df)} rows)\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35161e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Index return using Yahoo Finance (SPY as proxy for S&P 500)\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "index_symbol = \"SPY\"\n",
    "index_df = get_yfinance_data(index_symbol, start_date=start_date, end_date=end_date)\n",
    "\n",
    "# Ensure 'close' is float\n",
    "index_df[\"close\"] = index_df[\"close\"].astype(float)\n",
    "\n",
    "# Compute daily percent change\n",
    "index_df[\"Percent Change\"] = index_df[\"close\"].pct_change()\n",
    "\n",
    "# Compute cumulative return\n",
    "index_return = (index_df[\"Percent Change\"] + 1).cumprod().iloc[-1]\n",
    "\n",
    "print(f\"S&P 500 proxy return (SPY): {index_return:.2f}x\")\n",
    "print(index_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "TICKERS_FILE = \"tickers_sp500.csv\"  # üîπ file to store full table with sanitized tickers\n",
    "\n",
    "def tickers_sp500() -> list:\n",
    "    \"\"\"\n",
    "    Fetch S&P 500 tickers from Wikipedia, cache the full table to a CSV file\n",
    "    with sanitized tickers, and return a list of tickers for Yahoo Finance.\n",
    "\n",
    "    Returns:\n",
    "        list: List of ticker symbols formatted for Yahoo Finance (e.g., BRK-B instead of BRK.B).\n",
    "    \"\"\"\n",
    "    # üîπ Load from file if exists\n",
    "    if os.path.exists(TICKERS_FILE):\n",
    "        df = pd.read_csv(TICKERS_FILE)\n",
    "        tickers = df['Symbol'].dropna().tolist()\n",
    "        print(f\"üìÑ Loaded {len(tickers)} tickers from {TICKERS_FILE}\")\n",
    "        return tickers\n",
    "\n",
    "    # üîπ Fetch live data from Wikipedia\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    html = requests.get(url, headers=headers).text\n",
    "    df_list = pd.read_html(StringIO(html), header=0)\n",
    "    df = df_list[0]\n",
    "\n",
    "    # üîπ Sanitize tickers in the DataFrame\n",
    "    df['Symbol'] = df['Symbol'].str.replace('.', '-', regex=False)\n",
    "\n",
    "    # üîπ Save full table with sanitized tickers to CSV\n",
    "    df.to_csv(TICKERS_FILE, index=False)\n",
    "    print(f\"‚úÖ Saved full S&P 500 table with sanitized tickers to {TICKERS_FILE}\")\n",
    "\n",
    "    # üîπ Return list of tickers\n",
    "    tickers = df['Symbol'].dropna().tolist()\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a15bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = tickers_sp500()\n",
    "print(f\"‚úÖ Loaded {len(tickers)} S&P 500 tickers\")\n",
    "print(tickers[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global dictionary to store all ticker data\n",
    "yahoo_data = {}\n",
    "successful_tickers = []\n",
    "failed_tickers = []\n",
    "\n",
    "def load_yahoo_data(tickers):\n",
    "    \"\"\"\n",
    "    Fetch data once and store in global yahoo_data dictionary.\n",
    "    Writes passed and failed tickers to text files.\n",
    "    \"\"\"\n",
    "    global yahoo_data\n",
    "\n",
    "    for symbol in tickers:\n",
    "        df = get_yfinance_data(symbol, start_date=start_date, end_date=end_date)\n",
    "\n",
    "        if df.empty or \"close\" not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è Skipping {symbol}: No data or bad format\")\n",
    "            failed_tickers.append(symbol)\n",
    "            continue\n",
    "\n",
    "        yahoo_data[symbol] = df\n",
    "        successful_tickers.append(symbol)\n",
    "        print(f\"‚úÖ Loaded {symbol} successfully\")\n",
    "\n",
    "    # Write failed tickers to file\n",
    "    with open(\"failed_tickers.txt\", \"w\") as f:\n",
    "        for ticker in failed_tickers:\n",
    "            f.write(f\"{ticker}\\n\")\n",
    "\n",
    "    # Write successful tickers to file (optional)\n",
    "    with open(\"successful_tickers.txt\", \"w\") as f:\n",
    "        for ticker in successful_tickers:\n",
    "            f.write(f\"{ticker}\\n\")\n",
    "\n",
    "    print(f\"\\nüìÑ {len(successful_tickers)} tickers loaded successfully and saved to successful_tickers.txt\")\n",
    "    print(f\"üìÑ {len(failed_tickers)} tickers failed and saved to failed_tickers.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7108336",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_yahoo_data(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rs(index_return, start_date, end_date, index_symbol=\"SPY\"):\n",
    "    \"\"\"\n",
    "    Calculate RS scores using preloaded yahoo_data and precomputed index_return.\n",
    "    Only processes successful tickers from load_yahoo_data().\n",
    "    \"\"\"\n",
    "    global yahoo_data, successful_tickers\n",
    "\n",
    "    returns_multiples = []\n",
    "\n",
    "    for symbol in successful_tickers:\n",
    "        if symbol == index_symbol:\n",
    "            continue  # skip the index itself\n",
    "\n",
    "        df_subset = yahoo_data[symbol].loc[start_date:end_date].copy()\n",
    "        df_subset[\"close\"] = df_subset[\"close\"].astype(float)\n",
    "        df_subset[\"Percent Change\"] = df_subset[\"close\"].pct_change()\n",
    "        stock_return = (df_subset[\"Percent Change\"] + 1).cumprod().iloc[-1]\n",
    "        rs_score = stock_return / index_return\n",
    "        returns_multiples.append(rs_score)\n",
    "        print(f\"‚úÖ {symbol} processed ‚Äì RS Score: {rs_score:.2f}\")\n",
    "\n",
    "    return returns_multiples\n",
    "\n",
    "returns_multiples = calculate_rs(index_return, start_date, end_date)\n",
    "print(f\"\\nCalculated RS scores for {len(successful_tickers)} tickers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ce51030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_rs_top_df(successful_tickers, returns_multiples, top_quantile=0.7):\n",
    "    \"\"\"\n",
    "    Create RS Rating DataFrame and filter top stocks by percentile.\n",
    "    \n",
    "    Args:\n",
    "        successful_tickers (list): List of tickers successfully loaded.\n",
    "        returns_multiples (list): Corresponding return multiples for tickers.\n",
    "        top_quantile (float): Quantile threshold for top RS stocks (default 0.7).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Top RS stocks with columns ['Ticker', 'Returns_Multiple', 'RS_Rating'].\n",
    "    \"\"\"\n",
    "    rs_df = pd.DataFrame({\n",
    "        'Ticker': successful_tickers,\n",
    "        'Returns_Multiple': returns_multiples\n",
    "    })\n",
    "    rs_df['RS_Rating'] = rs_df['Returns_Multiple'].rank(pct=True) * 100\n",
    "\n",
    "    # Filter top stocks by RS_Rating quantile\n",
    "    threshold = rs_df['RS_Rating'].quantile(top_quantile)\n",
    "    rs_top_df = rs_df[rs_df['RS_Rating'] >= threshold].reset_index(drop=True)\n",
    "    return rs_top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b31ff6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minervini_report(yahoo_data, rs_top_df, export_prefix=\"Minervini\"):\n",
    "    \"\"\"\n",
    "    Generate Minervini report for top RS stocks without FutureWarning.\n",
    "    \"\"\"\n",
    "    rows = []  # Collect row dicts here instead of using concat in the loop\n",
    "\n",
    "    for stock in rs_top_df['Ticker']:\n",
    "        try:\n",
    "            df = yahoo_data.get(stock)\n",
    "            if df is None or df.empty:\n",
    "                print(f\"‚ö†Ô∏è No data for {stock}, skipping\")\n",
    "                continue\n",
    "\n",
    "            df.columns = [col.split(\". \")[-1] for col in df.columns]\n",
    "            df[['close', 'high', 'low']] = df[['close', 'high', 'low']].astype(float)\n",
    "\n",
    "            df['SMA_50'] = df['close'].rolling(50).mean()\n",
    "            df['SMA_150'] = df['close'].rolling(150).mean()\n",
    "            df['SMA_200'] = df['close'].rolling(200).mean()\n",
    "\n",
    "            currentClose = round(df['close'].iloc[-1], 2)\n",
    "            SMA_50 = round(df['SMA_50'].iloc[-1], 2)\n",
    "            SMA_150 = round(df['SMA_150'].iloc[-1], 2)\n",
    "            SMA_200 = round(df['SMA_200'].iloc[-1], 2)\n",
    "            low_52week = round(df['low'].iloc[-260:].min(), 2)\n",
    "            high_52week = round(df['high'].iloc[-260:].max(), 2)\n",
    "\n",
    "            Returns_Multiple = round(rs_top_df.loc[rs_top_df['Ticker'] == stock, 'Returns_Multiple'].iloc[0], 2)\n",
    "            RS_Rating = round(rs_top_df.loc[rs_top_df['Ticker'] == stock, 'RS_Rating'].iloc[0])\n",
    "\n",
    "            if pd.isnull([SMA_50, SMA_150, SMA_200]).any():\n",
    "                status_msg = f\"‚ùå Skipped {stock}: Not enough data for SMAs ({len(df)} rows)\"\n",
    "            else:\n",
    "                SMA_200_20 = df['SMA_200'].iloc[-20] if len(df) >= 220 else 0\n",
    "                conditions = [\n",
    "                    currentClose > SMA_150 > SMA_200,\n",
    "                    SMA_150 > SMA_200,\n",
    "                    SMA_200 > SMA_200_20,\n",
    "                    SMA_50 > SMA_150 > SMA_200,\n",
    "                    currentClose > SMA_50,\n",
    "                    currentClose >= 1.3 * low_52week,\n",
    "                    currentClose >= 0.75 * high_52week\n",
    "                ]\n",
    "                if all(conditions):\n",
    "                    status_msg = \"‚úÖ Passed Minervini\"\n",
    "                else:\n",
    "                    failed = [str(i+1) for i, c in enumerate(conditions) if not c]\n",
    "                    status_msg = f\"‚ùå Failed Minervini conditions: {', '.join(failed)}\"\n",
    "\n",
    "            # Add row dict to list\n",
    "            rows.append({\n",
    "                'Stock': stock,\n",
    "                'Price': currentClose,\n",
    "                '50 Day MA': SMA_50,\n",
    "                '150 Day MA': SMA_150,\n",
    "                '200 Day MA': SMA_200,\n",
    "                '52 Week Low': low_52week,\n",
    "                '52 Week High': high_52week,\n",
    "                'Returns_Multiple': Returns_Multiple,\n",
    "                'RS_Rating': RS_Rating,\n",
    "                'Status': status_msg\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not process {stock}: {e}\")\n",
    "\n",
    "    # Create DataFrame once at the end\n",
    "    detailedExportList = pd.DataFrame(rows)\n",
    "\n",
    "    # Split and sort\n",
    "    passed_df_sorted = detailedExportList[detailedExportList['Status'] == \"‚úÖ Passed Minervini\"] \\\n",
    "        .sort_values(by=['Returns_Multiple', 'Stock'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    failed_df_sorted = detailedExportList[detailedExportList['Status'] != \"‚úÖ Passed Minervini\"] \\\n",
    "        .sort_values(by=['Returns_Multiple', 'Stock'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    # Export\n",
    "    passed_df_sorted.to_csv(f\"{export_prefix}_Passed.csv\", index=False)\n",
    "    failed_df_sorted.to_csv(f\"{export_prefix}_Failed.csv\", index=False)\n",
    "\n",
    "    print(f\"\\nüìÑ {len(passed_df_sorted)} stocks passed Minervini, saved to {export_prefix}_Passed.csv\")\n",
    "    print(f\"üìÑ {len(failed_df_sorted)} stocks failed Minervini, saved to {export_prefix}_Failed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7f59927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ 72 stocks passed Minervini, saved to Minervini_Passed.csv\n",
      "üìÑ 79 stocks failed Minervini, saved to Minervini_Failed.csv\n"
     ]
    }
   ],
   "source": [
    "rs_top_df = create_rs_top_df(successful_tickers, returns_multiples)\n",
    "generate_minervini_report(yahoo_data, rs_top_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
