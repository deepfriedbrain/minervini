{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8aae94",
   "metadata": {},
   "source": [
    "Source Repo: https://github.com/wholidi/Project/tree/main/Minervini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"yfinance_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def get_yfinance_data(symbol: str, start_date: str, end_date: str, interval: str = \"1d\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch historical OHLCV data for a given ticker from Yahoo Finance, \n",
    "    using a cached file if available.\n",
    "\n",
    "    If a cached CSV file exists for the symbol, data is loaded from it.\n",
    "    Otherwise, live data is fetched from Yahoo Finance and saved to the cache.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): Ticker symbol (e.g., \"AAPL\", \"SPY\").\n",
    "        start_date (str): Start date for historical data in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date for historical data in 'YYYY-MM-DD' format.\n",
    "        interval (str): Data interval (\"1d\", \"1wk\", \"1mo\", etc.). Default is \"1d\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with timestamp index and columns: open, high, low, close, volume.\n",
    "                      Returns empty DataFrame if no data is found.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(DATA_DIR, f\"{symbol}.csv\")  # üîπ File name without date\n",
    "\n",
    "    # Load from cache if available\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        print(f\"üìÑ Loaded {symbol} data from file ({len(df)} rows)\")\n",
    "        return df\n",
    "\n",
    "    # Fetch live data\n",
    "    print(f\"Calling live API for {symbol}\")\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    df = ticker.history(start=start_date, end=end_date, interval=interval)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è No data found for {symbol}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df.index = df.index.tz_localize(None)  # remove timezone if present\n",
    "    df = df.rename(columns={\n",
    "        \"Open\": \"open\",\n",
    "        \"High\": \"high\",\n",
    "        \"Low\": \"low\",\n",
    "        \"Close\": \"close\",\n",
    "        \"Volume\": \"volume\"\n",
    "    })\n",
    "\n",
    "    df = df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "    # Save to cache\n",
    "    df.to_csv(file_path)\n",
    "    print(f\"‚úÖ Saved {symbol} data to {file_path} ({len(df)} rows)\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35161e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Index return using Yahoo Finance (SPY as proxy for S&P 500)\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "end_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "index_symbol = \"SPY\"\n",
    "index_df = get_yfinance_data(index_symbol, start_date=start_date, end_date=end_date)\n",
    "\n",
    "# Ensure 'close' is float\n",
    "index_df[\"close\"] = index_df[\"close\"].astype(float)\n",
    "\n",
    "# Compute daily percent change\n",
    "index_df[\"Percent Change\"] = index_df[\"close\"].pct_change()\n",
    "\n",
    "# Compute cumulative return\n",
    "index_return = (index_df[\"Percent Change\"] + 1).cumprod().iloc[-1]\n",
    "\n",
    "print(f\"S&P 500 proxy return (SPY): {index_return:.2f}x\")\n",
    "print(index_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "TICKERS_FILE = \"tickers_sp500.csv\"  # üîπ file to store full table with sanitized tickers\n",
    "\n",
    "def tickers_sp500() -> list:\n",
    "    \"\"\"\n",
    "    Fetch S&P 500 tickers from Wikipedia, cache the full table to a CSV file\n",
    "    with sanitized tickers, and return a list of tickers for Yahoo Finance.\n",
    "\n",
    "    Returns:\n",
    "        list: List of ticker symbols formatted for Yahoo Finance (e.g., BRK-B instead of BRK.B).\n",
    "    \"\"\"\n",
    "    # üîπ Load from file if exists\n",
    "    if os.path.exists(TICKERS_FILE):\n",
    "        df = pd.read_csv(TICKERS_FILE)\n",
    "        tickers = df['Symbol'].dropna().tolist()\n",
    "        print(f\"üìÑ Loaded {len(tickers)} tickers from {TICKERS_FILE}\")\n",
    "        return tickers\n",
    "\n",
    "    # üîπ Fetch live data from Wikipedia\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    html = requests.get(url, headers=headers).text\n",
    "    df_list = pd.read_html(StringIO(html), header=0)\n",
    "    df = df_list[0]\n",
    "\n",
    "    # üîπ Sanitize tickers in the DataFrame\n",
    "    df['Symbol'] = df['Symbol'].str.replace('.', '-', regex=False)\n",
    "\n",
    "    # üîπ Save full table with sanitized tickers to CSV\n",
    "    df.to_csv(TICKERS_FILE, index=False)\n",
    "    print(f\"‚úÖ Saved full S&P 500 table with sanitized tickers to {TICKERS_FILE}\")\n",
    "\n",
    "    # üîπ Return list of tickers\n",
    "    tickers = df['Symbol'].dropna().tolist()\n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a15bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = tickers_sp500()\n",
    "print(f\"‚úÖ Loaded {len(tickers)} S&P 500 tickers\")\n",
    "print(tickers[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global dictionary to store all ticker data\n",
    "yahoo_data = {}\n",
    "successful_tickers = []\n",
    "failed_tickers = []\n",
    "\n",
    "def load_yahoo_data(tickers):\n",
    "    \"\"\"\n",
    "    Fetch data once and store in global yahoo_data dictionary.\n",
    "    Writes passed and failed tickers to text files.\n",
    "    \"\"\"\n",
    "    global yahoo_data\n",
    "\n",
    "    for symbol in tickers:\n",
    "        df = get_yfinance_data(symbol, start_date=start_date, end_date=end_date)\n",
    "\n",
    "        if df.empty or \"close\" not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è Skipping {symbol}: No data or bad format\")\n",
    "            failed_tickers.append(symbol)\n",
    "            continue\n",
    "\n",
    "        yahoo_data[symbol] = df\n",
    "        successful_tickers.append(symbol)\n",
    "        print(f\"‚úÖ Loaded {symbol} successfully\")\n",
    "\n",
    "    # Write failed tickers to file\n",
    "    with open(\"failed_tickers.txt\", \"w\") as f:\n",
    "        for ticker in failed_tickers:\n",
    "            f.write(f\"{ticker}\\n\")\n",
    "\n",
    "    # Write successful tickers to file (optional)\n",
    "    with open(\"successful_tickers.txt\", \"w\") as f:\n",
    "        for ticker in successful_tickers:\n",
    "            f.write(f\"{ticker}\\n\")\n",
    "\n",
    "    print(f\"\\nüìÑ {len(successful_tickers)} tickers loaded successfully and saved to successful_tickers.txt\")\n",
    "    print(f\"üìÑ {len(failed_tickers)} tickers failed and saved to failed_tickers.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7108336",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_yahoo_data(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rs(index_return, start_date, end_date, index_symbol=\"SPY\"):\n",
    "    \"\"\"\n",
    "    Calculate RS scores using preloaded yahoo_data and precomputed index_return.\n",
    "    Only processes successful tickers from load_yahoo_data().\n",
    "    \"\"\"\n",
    "    global yahoo_data, successful_tickers\n",
    "\n",
    "    returns_multiples = []\n",
    "\n",
    "    for symbol in successful_tickers:\n",
    "        if symbol == index_symbol:\n",
    "            continue  # skip the index itself\n",
    "\n",
    "        df_subset = yahoo_data[symbol].loc[start_date:end_date].copy()\n",
    "        df_subset[\"close\"] = df_subset[\"close\"].astype(float)\n",
    "        df_subset[\"Percent Change\"] = df_subset[\"close\"].pct_change()\n",
    "        stock_return = (df_subset[\"Percent Change\"] + 1).cumprod().iloc[-1]\n",
    "        rs_score = stock_return / index_return\n",
    "        returns_multiples.append(rs_score)\n",
    "        print(f\"‚úÖ {symbol} processed ‚Äì RS Score: {rs_score:.2f}\")\n",
    "\n",
    "    return returns_multiples\n",
    "\n",
    "returns_multiples = calculate_rs(index_return, start_date, end_date)\n",
    "print(f\"\\nCalculated RS scores for {len(successful_tickers)} tickers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41faf96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Create RS Rating DataFrame\n",
    "rs_df = pd.DataFrame({\n",
    "    'Ticker': successful_tickers,\n",
    "    'Returns_multiple': returns_multiples\n",
    "})\n",
    "rs_df['RS_Rating'] = rs_df['Returns_multiple'].rank(pct=True) * 100\n",
    "\n",
    "# ‚úÖ Filter top 30% by RS Rating (adjust quantile as needed)\n",
    "top_30_percent = rs_df['RS_Rating'].quantile(0.7)\n",
    "rs_top_df = rs_df[rs_df['RS_Rating'] >= top_30_percent]\n",
    "\n",
    "print(rs_top_df[:10])\n",
    "# Print sorted top RS stocks\n",
    "print(rs_top_df.sort_values(by='RS_Rating', ascending=False).head(10))\n",
    "\n",
    "# ‚úÖ Export all RS-rated stocks without filtering\n",
    "rs_df.to_csv(\"rs_full_list.csv\", index=False)\n",
    "print(f\"üìä Full RS stock list: {len(rs_df)} saved to rs_full_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ce51030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ALLE passed Minervini\n",
      "‚ùå GOOGL failed Minervini: 1, 2, 4\n",
      "‚ùå GOOG failed Minervini: 1, 2, 4\n",
      "‚úÖ MO passed Minervini\n",
      "‚ùå AMZN failed Minervini: 1, 2, 4\n",
      "‚ùå AXP failed Minervini: 1, 2, 4\n",
      "‚úÖ APH passed Minervini\n",
      "‚ùå APO failed Minervini: 1, 2, 3, 4, 5, 7\n",
      "‚ùå ANET failed Minervini: 1, 2, 4\n",
      "‚úÖ T passed Minervini\n",
      "‚ùå ATO failed Minervini: 6\n",
      "‚úÖ AZO passed Minervini\n",
      "‚ùå AXON failed Minervini: 5\n",
      "‚ùå BKR failed Minervini: 1, 2, 4\n",
      "‚ùå BAC failed Minervini: 1, 2, 4\n",
      "‚ùå BLK failed Minervini: 1, 2, 4\n",
      "‚ùå BX failed Minervini: 1, 2, 3, 4\n",
      "‚úÖ BK passed Minervini\n",
      "‚ùå BA failed Minervini: 5\n",
      "‚ùå BKNG failed Minervini: 5\n",
      "‚ùå BSX failed Minervini: 1, 5, 6\n",
      "‚úÖ AVGO passed Minervini\n",
      "‚ùå CHRW failed Minervini: 1, 2, 4\n",
      "‚ùå CDNS failed Minervini: 1, 2, 4\n",
      "‚úÖ COF passed Minervini\n",
      "‚ùå CAH failed Minervini: 5\n",
      "‚ùå CCL failed Minervini: 1, 2, 4\n",
      "‚ùå CAT failed Minervini: 1, 2, 4\n",
      "‚úÖ CBRE passed Minervini\n",
      "‚ùå COR failed Minervini: 5\n",
      "‚úÖ CNP passed Minervini\n",
      "‚ùå SCHW failed Minervini: 5\n",
      "‚ùå CSCO failed Minervini: 5\n",
      "‚úÖ C passed Minervini\n",
      "‚ùå CFG failed Minervini: 1, 2, 4\n",
      "‚ùå CME failed Minervini: 1, 5, 6\n",
      "‚ùå COIN failed Minervini: 1, 2, 4, 5, 7\n",
      "‚úÖ CEG passed Minervini\n",
      "‚úÖ GLW passed Minervini\n",
      "‚ùå CTVA failed Minervini: 5\n",
      "‚ùå CRWD failed Minervini: 5\n",
      "‚ùå CMI failed Minervini: 1, 2, 4\n",
      "‚úÖ CVS passed Minervini\n",
      "‚úÖ DRI passed Minervini\n",
      "‚ùå DDOG failed Minervini: 1, 2, 4, 5\n",
      "‚ùå DAL failed Minervini: 1, 2, 3, 4\n",
      "‚ùå DG failed Minervini: 5\n",
      "‚ùå DLTR failed Minervini: 5\n",
      "‚úÖ DASH passed Minervini\n",
      "‚ùå ETN failed Minervini: 1, 2, 3, 4\n",
      "‚úÖ EBAY passed Minervini\n",
      "‚úÖ EA passed Minervini\n",
      "‚ùå EMR failed Minervini: 1, 2, 4, 5\n",
      "‚úÖ ETR passed Minervini\n",
      "‚ùå EQT failed Minervini: 1, 4, 5\n",
      "‚ùå EVRG failed Minervini: 6\n",
      "‚ùå EXE failed Minervini: 1, 4, 5\n",
      "‚ùå EXPE failed Minervini: 1, 2, 4\n",
      "‚úÖ FFIV passed Minervini\n",
      "‚ùå FAST failed Minervini: 5\n",
      "‚úÖ FOXA passed Minervini\n",
      "‚ùå FOX failed Minervini: 5\n",
      "‚ùå BEN failed Minervini: 5\n",
      "‚úÖ GRMN passed Minervini\n",
      "‚úÖ GE passed Minervini\n",
      "‚úÖ GEV passed Minervini\n",
      "‚ùå GNRC failed Minervini: 1, 2, 4\n",
      "‚ùå GM failed Minervini: 1, 2, 4\n",
      "‚ùå GILD failed Minervini: 5\n",
      "‚úÖ GL passed Minervini\n",
      "‚úÖ GS passed Minervini\n",
      "‚ùå HPE failed Minervini: 1, 2, 4\n",
      "‚úÖ HLT passed Minervini\n",
      "‚úÖ HWM passed Minervini\n",
      "‚ùå HBAN failed Minervini: 1, 2, 4\n",
      "‚úÖ IBM passed Minervini\n",
      "‚úÖ IDXX passed Minervini\n",
      "‚ùå INCY failed Minervini: 1, 2, 4\n",
      "‚úÖ PODD passed Minervini\n",
      "‚ùå IBKR failed Minervini: 5\n",
      "‚ùå IVZ failed Minervini: 1, 2, 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\364358\\AppData\\Local\\Temp\\ipykernel_10908\\2901662644.py:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  detailedExportList = pd.concat([detailedExportList, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå JBL failed Minervini: 5\n",
      "‚ùå J failed Minervini: 1, 2, 4\n",
      "‚úÖ JCI passed Minervini\n",
      "‚úÖ JPM passed Minervini\n",
      "‚ùå KMI failed Minervini: 1, 2, 4\n",
      "‚úÖ KLAC passed Minervini\n",
      "‚ùå KR failed Minervini: 1, 5, 6\n",
      "‚úÖ LHX passed Minervini\n",
      "‚úÖ LH passed Minervini\n",
      "‚úÖ LRCX passed Minervini\n",
      "‚ùå LVS failed Minervini: 1, 2, 4, 5\n",
      "‚úÖ LYV passed Minervini\n",
      "‚ùå L failed Minervini: 6\n",
      "‚ùå MCK failed Minervini: 5\n",
      "‚úÖ META passed Minervini\n",
      "‚úÖ MU passed Minervini\n",
      "‚úÖ MNST passed Minervini\n",
      "‚úÖ MS passed Minervini\n",
      "‚ùå MOS failed Minervini: 5\n",
      "‚ùå NDAQ failed Minervini: 5\n",
      "‚ùå NFLX failed Minervini: 5\n",
      "‚úÖ NEM passed Minervini\n",
      "‚úÖ NTRS passed Minervini\n",
      "‚ùå NCLH failed Minervini: 1, 2, 3, 4\n",
      "‚úÖ NRG passed Minervini\n",
      "‚úÖ NVDA passed Minervini\n",
      "‚úÖ ORLY passed Minervini\n",
      "‚úÖ ORCL passed Minervini\n",
      "‚úÖ PLTR passed Minervini\n",
      "‚úÖ PSKY passed Minervini\n",
      "‚úÖ PH passed Minervini\n",
      "‚ùå PAYC failed Minervini: 1, 4, 5\n",
      "‚ùå PM failed Minervini: 1, 5\n",
      "‚ùå PWR failed Minervini: 5\n",
      "‚úÖ RL passed Minervini\n",
      "‚ùå RJF failed Minervini: 1, 2, 4\n",
      "‚úÖ RTX passed Minervini\n",
      "‚ùå RF failed Minervini: 1, 2, 4\n",
      "‚ùå ROK failed Minervini: 5\n",
      "‚ùå RCL failed Minervini: 5\n",
      "‚úÖ STX passed Minervini\n",
      "‚ùå SNA failed Minervini: 1, 2, 3, 4, 6\n",
      "‚ùå STT failed Minervini: 5\n",
      "‚ùå STLD failed Minervini: 3\n",
      "‚ùå SYF failed Minervini: 1, 2, 4\n",
      "‚úÖ TTWO passed Minervini\n",
      "‚úÖ TPR passed Minervini\n",
      "‚úÖ TEL passed Minervini\n",
      "‚úÖ TDY passed Minervini\n",
      "‚ùå TSLA failed Minervini: 1, 2, 4\n",
      "‚úÖ TKO passed Minervini\n",
      "‚ùå TRMB failed Minervini: 1, 2, 4, 5\n",
      "‚úÖ UBER passed Minervini\n",
      "‚úÖ ULTA passed Minervini\n",
      "‚ùå UAL failed Minervini: 1, 2, 4\n",
      "‚ùå URI failed Minervini: 1, 2, 4\n",
      "‚úÖ VLO passed Minervini\n",
      "‚úÖ VRSN passed Minervini\n",
      "‚úÖ VST passed Minervini\n",
      "‚ùå VMC failed Minervini: 1, 2, 4\n",
      "‚úÖ WRB passed Minervini\n",
      "‚úÖ WMT passed Minervini\n",
      "‚ùå DIS failed Minervini: 1, 2, 4, 5\n",
      "‚úÖ WBD passed Minervini\n",
      "‚úÖ WFC passed Minervini\n",
      "‚úÖ WELL passed Minervini\n",
      "‚úÖ WDC passed Minervini\n",
      "‚ùå WSM failed Minervini: 1, 2, 4\n",
      "‚úÖ WMB passed Minervini\n",
      "‚úÖ WYNN passed Minervini\n",
      "\n",
      "üìÑ 72 stocks passed Minervini, saved to Minervini_Passed.csv\n",
      "üìÑ 79 stocks failed Minervini, saved to Minervini_Failed.csv\n"
     ]
    }
   ],
   "source": [
    "# üìå Initialize export DataFrame\n",
    "detailedExportList = pd.DataFrame(columns=[\n",
    "    'Stock', 'Price', '50 Day MA', '150 Day MA', '200 Day MA', \n",
    "    '52 Week Low', '52 Week High', 'RS_Rating', 'Status'  # üîπ CHANGED\n",
    "])\n",
    "\n",
    "# ‚úÖ Iterate only over top RS stocks\n",
    "for stock in rs_top_df['Ticker']:\n",
    "    try:\n",
    "        # Use already loaded data\n",
    "        df = yahoo_data.get(stock)\n",
    "        if df is None or df.empty:\n",
    "            print(f\"‚ö†Ô∏è No data for {stock}, skipping\")\n",
    "            continue\n",
    "\n",
    "        # Clean and prep columns\n",
    "        df.columns = [col.split(\". \")[-1] for col in df.columns]\n",
    "        df[['close', 'high', 'low']] = df[['close', 'high', 'low']].astype(float)\n",
    "\n",
    "        # Compute SMAs\n",
    "        df['SMA_50'] = df['close'].rolling(window=50).mean()\n",
    "        df['SMA_150'] = df['close'].rolling(window=150).mean()\n",
    "        df['SMA_200'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "        # Grab latest values\n",
    "        currentClose = df['close'].iloc[-1]\n",
    "        SMA_50 = df['SMA_50'].iloc[-1]\n",
    "        SMA_150 = df['SMA_150'].iloc[-1]\n",
    "        SMA_200 = df['SMA_200'].iloc[-1]\n",
    "\n",
    "        # 52-week high/low\n",
    "        low_52week = round(df['low'].iloc[-260:].min(), 2)\n",
    "        high_52week = round(df['high'].iloc[-260:].max(), 2)\n",
    "\n",
    "        # RS Rating\n",
    "        RS_Rating = round(rs_top_df.loc[rs_top_df['Ticker'] == stock, 'RS_Rating'].iloc[0])\n",
    "\n",
    "        # Handle insufficient SMA data\n",
    "        if pd.isnull([SMA_50, SMA_150, SMA_200]).any():\n",
    "            status_msg = f\"‚ùå Skipped {stock}: Not enough data for SMAs ({len(df)} rows)\"\n",
    "            print(status_msg)\n",
    "        else:\n",
    "            # Compare 200-day SMA 20 days ago\n",
    "            SMA_200_20 = df['SMA_200'].iloc[-20] if len(df) >= 220 else 0\n",
    "\n",
    "            # Minervini conditions\n",
    "            condition_1 = currentClose > SMA_150 > SMA_200\n",
    "            condition_2 = SMA_150 > SMA_200\n",
    "            condition_3 = SMA_200 > SMA_200_20\n",
    "            condition_4 = SMA_50 > SMA_150 > SMA_200\n",
    "            condition_5 = currentClose > SMA_50\n",
    "            condition_6 = currentClose >= 1.3 * low_52week\n",
    "            condition_7 = currentClose >= 0.75 * high_52week\n",
    "\n",
    "            conditions = [condition_1, condition_2, condition_3, condition_4,\n",
    "                          condition_5, condition_6, condition_7]\n",
    "\n",
    "            if all(conditions):\n",
    "                status_msg = \"‚úÖ Passed Minervini\"\n",
    "                print(f\"‚úÖ {stock} passed Minervini\")\n",
    "            else:\n",
    "                failed = [str(i+1) for i, c in enumerate(conditions) if not c]\n",
    "                status_msg = f\"‚ùå Failed Minervini conditions: {', '.join(failed)}\"\n",
    "                print(f\"‚ùå {stock} failed Minervini: {', '.join(failed)}\")\n",
    "\n",
    "        # Append to export list once per stock\n",
    "        detailedExportList = pd.concat([detailedExportList, pd.DataFrame([{\n",
    "            'Stock': stock,\n",
    "            'Price': currentClose,\n",
    "            '50 Day MA': SMA_50,\n",
    "            '150 Day MA': SMA_150,\n",
    "            '200 Day MA': SMA_200,\n",
    "            '52 Week Low': low_52week,\n",
    "            '52 Week High': high_52week,\n",
    "            'RS_Rating': RS_Rating,\n",
    "            'Status': status_msg\n",
    "        }])], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not process {stock}: {e}\")\n",
    "\n",
    "# ‚úÖ Split results\n",
    "passed_df = detailedExportList[detailedExportList['Status'] == \"‚úÖ Passed Minervini\"]\n",
    "failed_df = detailedExportList[detailedExportList['Status'] != \"‚úÖ Passed Minervini\"]\n",
    "\n",
    "# Sort passed DataFrame by descending RS_Rating, then ascending Stock\n",
    "passed_df_sorted = passed_df.sort_values(\n",
    "    by=['RS_Rating', 'Stock'],\n",
    "    ascending=[False, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Sort failed DataFrame by descending RS_Rating, then ascending Stock\n",
    "failed_df_sorted = failed_df.sort_values(\n",
    "    by=['RS_Rating', 'Stock'],\n",
    "    ascending=[False, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Export to CSV\n",
    "passed_df_sorted.to_csv(\"Minervini_Passed.csv\", index=False)\n",
    "failed_df_sorted.to_csv(\"Minervini_Failed.csv\", index=False)\n",
    "\n",
    "# # üì§ Export to Excel\n",
    "# passed_df_sorted.to_excel(\"Minervini_Passed.xlsx\", index=False)\n",
    "# failed_df_sorted.to_excel(\"Minervini_Failed.xlsx\", index=False)\n",
    "\n",
    "print(f\"\\nüìÑ {len(passed_df_sorted)} stocks passed Minervini, saved to Minervini_Passed.csv\")\n",
    "print(f\"üìÑ {len(failed_df_sorted)} stocks failed Minervini, saved to Minervini_Failed.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
